{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ironny_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxdgU+GQxeM8kG+nqAJrId",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/champ-rtu/Project2/blob/main/Ironny_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx4a7MGabQc4"
      },
      "source": [
        "#Import Libraty \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbkbnhokAUC4"
      },
      "source": [
        "**There are 6 section in this project**\n",
        "1. Import data\n",
        "2. Preprocessing \n",
        "3. Numerical representation\n",
        "4. Oversampling\n",
        "5. Train the data by machine learning models\n",
        "6. Evaluation in Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn8aAlaXLGk8"
      },
      "source": [
        "#**Import text data** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC2wKm2HZiap"
      },
      "source": [
        "Train and validataion data are imported in this section\n",
        "there are two data in this project which is raw text and label data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK9ed_5RbYmC"
      },
      "source": [
        "#Read raw text data and label data\n",
        "#Open train_text file \n",
        "x = []\n",
        "x_t = []\n",
        "with open('train_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    x.append(row)\n",
        "    x_t.append(row)\n",
        "\n",
        "#Open train_label file \n",
        "y = []\n",
        "y_t = []\n",
        "with open('train_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    y.append(row)\n",
        "    y_t.append(row)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqZyyIF-bYqy"
      },
      "source": [
        "#Read raw text data and label data\n",
        "#Open val_text file \n",
        "x_val = []\n",
        "with open('val_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    x.append(row)\n",
        "    x_val.append(row)\n",
        "\n",
        "#Open val_label file \n",
        "y_val = []\n",
        "with open('train_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    y.append(row)\n",
        "    y_val.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yRUVelzxbYod",
        "outputId": "4054c4d3-cdd2-495a-e11a-7c9158c7f1dc"
      },
      "source": [
        "#combine both data to dataframe\n",
        "data = pd.DataFrame(zip(x, y),  columns=['Comments', 'Labels'] )\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seeing ppl walking w/ crutches makes me really...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>look for the girl with the broken smile, ask h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Now I remember why I buy books online @user #s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user So is he banded from wearing the c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just found out there are Etch A Sketch apps.  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  seeing ppl walking w/ crutches makes me really...      1\n",
              "1  look for the girl with the broken smile, ask h...      0\n",
              "2  Now I remember why I buy books online @user #s...      1\n",
              "3  @user @user So is he banded from wearing the c...      1\n",
              "4  Just found out there are Etch A Sketch apps.  ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOogp3H9bYsr",
        "outputId": "32e8c373-1d82-4b14-f207-07298394cdbf"
      },
      "source": [
        "# check the number  of data\n",
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2862, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyeSU5J8bYvA",
        "outputId": "a2280e4d-e2f9-4055-ebfd-1fc9aa9b0acc"
      },
      "source": [
        "#Identify label data\n",
        "# It is a slight unbalanced class dataset\n",
        "data['Labels'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1445\n",
              "0    1417\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr0sloR2LbVZ"
      },
      "source": [
        "# **Preprocessing**\n",
        "For preprocessing. the process consists of \n",
        "1. tokenize\n",
        "2. lowercase transformation\n",
        "3. Remove punctuation and stopword\n",
        "4. Steming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_G7NJkDbYzb",
        "outputId": "ff40b951-41c9-4bda-c447-47e06dd01115"
      },
      "source": [
        "#import library for preprocessing step\n",
        "import nltk\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMTVmanQbY1h",
        "outputId": "5bfdf1af-612a-48e2-d70f-e93b0e151db6"
      },
      "source": [
        "#create punctuation, stopword and stem \n",
        "punct = string.punctuation #create list of punctuation\n",
        "stopwords = list(STOP_WORDS) #create list of stopword\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "ps = PorterStemmer() #steming\n",
        "STOP_WORDS.add('user') #because the text data contain a lot of user. So \"user\" is added in stopword.\n",
        "nlp.vocab['user'].is_stop # confirm that user is stopword "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgyIMUCAbY3_"
      },
      "source": [
        "#Create fucction for preprocessing step\n",
        "#the first function is remove punctuation, covert text to lower case\n",
        "def preprocessing_1(text):\n",
        "  txt = re.sub(r'\\d+','', text)\n",
        "  txt = txt.translate(str.maketrans(\"\",\"\",punct))\n",
        "  txt = txt.lower()\n",
        "  txt = txt.strip()\n",
        "  return txt\n",
        "\n",
        "#For the second function; tokenization and remove stopwords\n",
        "def preprocessing_2(text):\n",
        "  txt = word_tokenize(text)\n",
        "  txt = [i for i in txt if not i in stopwords]\n",
        "  txt = txt = \" \".join(txt)\n",
        "  return txt\n",
        "\n",
        "#The last function; stemming\n",
        "def stem(text):\n",
        "  txt = word_tokenize(text)\n",
        "  txt = [ps.stem(i) for i in txt ]\n",
        "  txt = txt = \" \".join(txt)\n",
        "  return txt\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HY_SLGqObY8N",
        "outputId": "e5154d85-127a-42d1-fcf9-2946a727a13b"
      },
      "source": [
        "#Apply preprocessing function to the dataset\n",
        "data['Comments'] = data['Comments'].apply(lambda x: preprocessing_1(x))\n",
        "data['Comments'] = data['Comments'].apply(lambda x: preprocessing_2(x))\n",
        "data['Comments'] = data['Comments'].apply(lambda x: stem(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>see ppl walk w crutch make excit week life</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>look girl broken smile ask want stay love ðŸ’•ðŸŽµ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rememb buy book onlin user servicewithasmil</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user user band wear cloth karma</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>found etch sketch app oldschool notoldschool</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Comments Labels\n",
              "0    see ppl walk w crutch make excit week life      1\n",
              "1  look girl broken smile ask want stay love ðŸ’•ðŸŽµ      0\n",
              "2   rememb buy book onlin user servicewithasmil      1\n",
              "3               user user band wear cloth karma      1\n",
              "4  found etch sketch app oldschool notoldschool      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUNYzQHybY-0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7KSIN22Lmos"
      },
      "source": [
        "# **Feature exaction section**\n",
        "In the process, two feature extraction method were selected \n",
        "  1. CounterVectorizer\n",
        "  2. TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPYt1poObqxw"
      },
      "source": [
        "#import importance library for feature extraction method\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7OIA25BbsC8"
      },
      "source": [
        "#split dataset to x and y variables\n",
        "y = data['Labels']\n",
        "x = data['Comments']\n",
        "#applied TF-IDF approach\n",
        "tf=TfidfVectorizer() \n",
        "x_tf = tf.fit_transform(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITciEjhpbsFb"
      },
      "source": [
        "#applied CountVectorizer\n",
        "ct = CountVectorizer()\n",
        "x_ct = ct.fit_transform(x)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JxTyNw-bsHq"
      },
      "source": [
        "#Split train and test dataset tf-idf approach\n",
        "X_train, X_test, y_train, y_test =  train_test_split(x_tf, y, test_size = 0.3,\n",
        "                                                     random_state =0, shuffle = True)\n",
        "#Split train and test dataset couter vectorizer approach\n",
        "X_train_c, X_test_c, y_train_c, y_test_c =  train_test_split(x_ct, y, test_size = 0.3, \n",
        "                                                             random_state =0, shuffle = True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxwnsLqzbvOP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmjgNc_EL4fz"
      },
      "source": [
        "# **Oversampling approach**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHYRT6L9bvQ8",
        "outputId": "68f9ec98-b653-4fb7-c97e-73def42e2a90"
      },
      "source": [
        "#import library for oversampling\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "os =  RandomOverSampler( )\n",
        "X_sm, y_sm = os.fit_sample(X_train, y_train) #apply Oversampling to x train with TFIDF method \n",
        "Xc_sm, yc_sm = os.fit_sample(X_train_c, y_train_c) #apply Oversampling to x train with CounterVectorizer method "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c-HFjiob-DB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94fcea51-7aba-49c1-bf6e-5b4c5de30c83"
      },
      "source": [
        "#Check dimension after oversampling approach\n",
        "X_sm.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2058, 6517)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckqwJ7bFMBBW"
      },
      "source": [
        "# **Train data**\n",
        "Three machine learning algorithms are selected for data training \n",
        "1. Logistic regression\n",
        "2. Support vector machine\n",
        "3. Randomforest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0qdwDuVMGPc"
      },
      "source": [
        "**Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bt_t1Q1b-F5"
      },
      "source": [
        "#Import library\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0nhKInib-H3"
      },
      "source": [
        "#Create logistic regression model\n",
        "log_class=LogisticRegression()\n",
        "# created dict which use for Gridsearch\n",
        "grid={'C':10.0 **np.arange(-3,4),'penalty':['l1','l2']}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0auZU9QbvVl",
        "outputId": "a977275e-11f0-4582-f7ab-940f2dde9925"
      },
      "source": [
        "#Applied Gridsearch for parameter tuning and train with TF-IDF as input\n",
        "log=GridSearchCV(estimator=log_class,param_grid=grid,cv=5,n_jobs=-1,scoring='f1_macro')\n",
        "log.fit(X_sm,y_sm)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER_iWVCobvXo",
        "outputId": "7f0be81e-a38b-43d8-8fcc-0f467bfe9129"
      },
      "source": [
        "#Applied Gridsearch for parameter tuning and train with Counter vector as input\n",
        "log_c=GridSearchCV(estimator=log_class,param_grid=grid,cv=5,n_jobs=-1,scoring='f1_macro')\n",
        "log_c.fit(Xc_sm,yc_sm)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoddT-xFBTL2"
      },
      "source": [
        "Evaluation training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWOkxldScLoW"
      },
      "source": [
        "#import library for evaluation\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CoaNl0xcLrH",
        "outputId": "f346f720-ca54-4fdd-ea4a-92d9a3fc1d7c"
      },
      "source": [
        "#Prediction and Evaluation the model with TF-IDF as input\n",
        "y_pred_log=log.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_log))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67       443\n",
            "           1       0.64      0.64      0.64       416\n",
            "\n",
            "    accuracy                           0.66       859\n",
            "   macro avg       0.66      0.65      0.66       859\n",
            "weighted avg       0.66      0.66      0.66       859\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZiaJKtncLtl",
        "outputId": "aa0e1735-3b9d-4045-d8db-b54436b8735a"
      },
      "source": [
        "#Prediction and Evaluation the model with CounterVectorizer as input\n",
        "y_pred_logc=log_c.predict(X_test_c)\n",
        "print(classification_report(y_test,y_pred_logc))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.62      0.64       443\n",
            "           1       0.62      0.64      0.63       416\n",
            "\n",
            "    accuracy                           0.63       859\n",
            "   macro avg       0.63      0.63      0.63       859\n",
            "weighted avg       0.63      0.63      0.63       859\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GPIFWJWcLvQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuJgDX-3MKHA"
      },
      "source": [
        "**Support vector machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73egHLEacLx-"
      },
      "source": [
        "#Import and create svm models for train different input (TFIDF, count vector)\n",
        "from sklearn import svm\n",
        "#Fit with TF-IDF\n",
        "svc1 = svm.LinearSVC(C=10)\n",
        "#Fit with Countervectorizer\n",
        "svc2 = svm.LinearSVC(C=10)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2hBaRy3cLzq",
        "outputId": "1594fb5e-8083-422d-a485-f217faa7a14a"
      },
      "source": [
        "#Training data \n",
        "svc1.fit(X_sm,y_sm) #TF-IDF method\n",
        "svc2.fit(Xc_sm,yc_sm) #CounterVectorizer approach\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V1oV6TPceC5"
      },
      "source": [
        "#Evaluation in training set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30rFvv7lcL4X",
        "outputId": "0ece444c-8716-473d-ac07-f9cde632db73"
      },
      "source": [
        "#Prediction and Evaluation the model with TF-IDF as input for training phase\n",
        "y_pred=svc1.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.58      0.60       443\n",
            "           1       0.58      0.61      0.59       416\n",
            "\n",
            "    accuracy                           0.60       859\n",
            "   macro avg       0.60      0.60      0.60       859\n",
            "weighted avg       0.60      0.60      0.60       859\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLGzBvINcL6V",
        "outputId": "c645a471-24a9-46be-deb0-d10d6a323723"
      },
      "source": [
        "#Prediction and Evaluation the model with CounterVectorizer as input for training phase\n",
        "y_pred_c=svc2.predict(X_test_c)\n",
        "print(classification_report(y_test,y_pred_c))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.61      0.62       443\n",
            "           1       0.60      0.61      0.60       416\n",
            "\n",
            "    accuracy                           0.61       859\n",
            "   macro avg       0.61      0.61      0.61       859\n",
            "weighted avg       0.61      0.61      0.61       859\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV3BcDUccL9P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMk27ApqMgDD"
      },
      "source": [
        "**Randomforest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koLtekcZMfff"
      },
      "source": [
        "#import library and create Randomforest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Create models\n",
        "clf_forest = RandomForestClassifier()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJW_4lQGM05V"
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [50,100,200]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-Ff1Y-IMfiO",
        "outputId": "96206f8d-a2b9-412f-b03e-7c4d59de0b62"
      },
      "source": [
        "#import library and create Randomforest model\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "rf_random = RandomizedSearchCV(estimator = clf_forest, \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, cv = 3, verbose=2, \n",
        "                               random_state=42, n_jobs = -1)\n",
        "rf_random.fit(X_sm,y_sm) #Train model with TF-IDF input"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=None,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [50, 100, 200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3frZ4w8Mfkl",
        "outputId": "3f7b6ccb-01bd-4c41-fd9b-04b40bac3961"
      },
      "source": [
        "rf_random_c = RandomizedSearchCV(estimator = clf_forest, \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, cv = 3, verbose=2, \n",
        "                               random_state=42, n_jobs = -1)\n",
        "rf_random_c.fit(Xc_sm,yc_sm) #Train model with Count vector input"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=None,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [50, 100, 200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mio6W-yACOVC"
      },
      "source": [
        "Evaluation in training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT7xp-QDcL-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf38d90-9a1f-4394-f06e-cc3598c642ca"
      },
      "source": [
        "#Prediction and Evaluation the model with TF-IDF as input for training phase\n",
        "y_pred_rf=rf_random.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_rf))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.79      0.70       443\n",
            "           1       0.69      0.49      0.57       416\n",
            "\n",
            "    accuracy                           0.65       859\n",
            "   macro avg       0.66      0.64      0.64       859\n",
            "weighted avg       0.66      0.65      0.64       859\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2ezstqpX-KE",
        "outputId": "8f61ffb1-031b-4ac1-ee6d-1392c21ae80e"
      },
      "source": [
        "#Prediction and Evaluation the model with CounterVectorizer as input for training phase\n",
        "y_pred_rfc=rf_random_c.predict(X_test_c)\n",
        "print(classification_report(y_test,y_pred_rfc))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.75      0.69       443\n",
            "           1       0.67      0.55      0.61       416\n",
            "\n",
            "    accuracy                           0.65       859\n",
            "   macro avg       0.66      0.65      0.65       859\n",
            "weighted avg       0.66      0.65      0.65       859\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnryrcsrX-Vg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d0AFD8jYSRL"
      },
      "source": [
        "# **Classify and predict in test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tqkxorClcMAr",
        "outputId": "09d38a48-01f0-4fa3-ecec-6f805d860550"
      },
      "source": [
        "#Read Test dataset with include raw text and labels\n",
        "#Open test_text \n",
        "xt = []\n",
        "with open('test_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    xt.append(row)\n",
        "\n",
        " #Open test_label\n",
        "yt = []\n",
        "with open('test_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    yt.append(row)   \n",
        "\n",
        "data_t = pd.DataFrame(zip(xt, yt),  columns=['Comments', 'Labels'] )\n",
        "data_t.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Can U Help?||More conservatives needed o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#NOT GONNA WIN \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user He is exactly that sort of person. Weird...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So much #sarcasm at work mate 10/10 #boring 10...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  @user Can U Help?||More conservatives needed o...      0\n",
              "1  Just walked in to #Starbucks and asked for a \"...      1\n",
              "2                                  #NOT GONNA WIN \\n      0\n",
              "3  @user He is exactly that sort of person. Weird...      0\n",
              "4  So much #sarcasm at work mate 10/10 #boring 10...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gyNOW1T5cMDE",
        "outputId": "fc600d3a-6980-4795-b2dd-8bea4f6bbef7"
      },
      "source": [
        "#Preprocessing in test file\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: preprocessing_1(x))\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: preprocessing_2(x))\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: stem(x))\n",
        "\n",
        "data_t.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user u helpmor conserv need tsu paid post stuf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>walk starbuck ask tall blond hahahaha ironi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gon na win</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user exactli sort person weirdo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sarcasm work mate bore dead mate shit absolut ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  user u helpmor conserv need tsu paid post stuf...      0\n",
              "1        walk starbuck ask tall blond hahahaha ironi      1\n",
              "2                                         gon na win      0\n",
              "3                    user exactli sort person weirdo      0\n",
              "4  sarcasm work mate bore dead mate shit absolut ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86FySpVmcMFL"
      },
      "source": [
        "#Feature extraction in test dataset by use two method\n",
        "x_tf_test = tf.transform(data_t['Comments']) #TF-IDF\n",
        "xc_tf_test = ct.transform(data_t['Comments']) #CounterVectorizer"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1gDOZlYCgdm"
      },
      "source": [
        "**Evaluated test dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZC3Zu4-Ycxl"
      },
      "source": [
        "Support vector machine evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzb_2HIXcx3h",
        "outputId": "1a7cb8c4-704f-4c9b-b3a8-a1dd6be0636c"
      },
      "source": [
        "#Evaluate support vector machine with tf-idf approach\n",
        "y_svc1 = svc1.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_svc1))\n",
        "f1_score(data_t['Labels'], y_svc1, average='macro')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.55      0.60       473\n",
            "           1       0.47      0.60      0.52       311\n",
            "\n",
            "    accuracy                           0.57       784\n",
            "   macro avg       0.57      0.57      0.56       784\n",
            "weighted avg       0.59      0.57      0.57       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5640264757264831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbX5sjVFcx6I",
        "outputId": "aa7c0707-1b96-4c8e-f60e-7e393cf0f03b"
      },
      "source": [
        "#Evaluate support vector machine with countervectorize approach\n",
        "y_svc2 = svc2.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_svc2))\n",
        "f1_score(data_t['Labels'], y_svc2, average='macro')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.56      0.62       473\n",
            "           1       0.48      0.62      0.54       311\n",
            "\n",
            "    accuracy                           0.59       784\n",
            "   macro avg       0.59      0.59      0.58       784\n",
            "weighted avg       0.61      0.59      0.59       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5832195736637615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dkC67QiYh73"
      },
      "source": [
        "Logistic regression Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNNVRbpJcx_V",
        "outputId": "df8a1221-b584-471c-f495-75235fe9a081"
      },
      "source": [
        "#Evaluate Logistic regression machine with tf-idf approach\n",
        "y_log1 = log.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_log1))\n",
        "f1_score(data_t['Labels'], y_log1, average='macro')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.60      0.66       473\n",
            "           1       0.52      0.66      0.58       311\n",
            "\n",
            "    accuracy                           0.62       784\n",
            "   macro avg       0.62      0.63      0.62       784\n",
            "weighted avg       0.64      0.62      0.63       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.618476430976431"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO5YNeg9cMHv",
        "outputId": "ec5c4e94-4da2-4213-e695-5f3f0ee1f5f4"
      },
      "source": [
        "#Evaluate Logistic regression machine with CounterVectorize approach\n",
        "y_logc = log_c.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'], y_logc))\n",
        "f1_score(data_t['Labels'], y_logc, average='macro')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.56      0.62       473\n",
            "           1       0.48      0.62      0.54       311\n",
            "\n",
            "    accuracy                           0.58       784\n",
            "   macro avg       0.59      0.59      0.58       784\n",
            "weighted avg       0.61      0.58      0.59       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5794591668512094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-UC0v9nY4Ii"
      },
      "source": [
        "Random forest evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOg4VmO8Y8iX",
        "outputId": "25c0a845-d1e0-4002-9152-e82f2f050bdf"
      },
      "source": [
        "#Evaluate Randomforest with CounterVectorizer approach\n",
        "y_rfc = rf_random.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_rfc))\n",
        "f1_score(data_t['Labels'], y_rfc, average='macro')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.66      0.69       473\n",
            "           1       0.54      0.60      0.57       311\n",
            "\n",
            "    accuracy                           0.64       784\n",
            "   macro avg       0.63      0.63      0.63       784\n",
            "weighted avg       0.64      0.64      0.64       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6266835080121699"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLsAbdwqY8k8",
        "outputId": "2cbc1a38-3166-4872-c8f9-031a341cf21f"
      },
      "source": [
        "#Evaluate Randomforest with tf-idf approach\n",
        "y_rf = rf_random.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_rf))\n",
        "f1_score(data_t['Labels'], y_rf, average='macro')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.71      0.70       473\n",
            "           1       0.54      0.51      0.53       311\n",
            "\n",
            "    accuracy                           0.64       784\n",
            "   macro avg       0.62      0.61      0.62       784\n",
            "weighted avg       0.63      0.64      0.63       784\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6153777539916154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTG5yWXLY8nI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}