{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hate speech_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUlg9O52jzCt2VkZgFvWkr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/champ-rtu/Project2/blob/main/Hate_speech_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcqv9Tu8NHDO"
      },
      "source": [
        "#Import Libraty \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvHo49i3yaex"
      },
      "source": [
        "**There are 6 section in this project**\n",
        "1. Import data\n",
        "2. Preprocessing \n",
        "3. Numerical representation\n",
        "4. Oversampling\n",
        "5. Train the data by machine learning models\n",
        "6. Evaluation in Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkH9rrXJVYkR"
      },
      "source": [
        "#**Import text data** \n",
        "Train and validataion data are imported in this section\n",
        "there are two data in this project which is raw text and label data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzZYXSp0VBvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e2b02a4d-c863-4bf9-e09f-638571f79338"
      },
      "source": [
        "#Read raw text data and label data\n",
        "#Open train_text file \n",
        "x = []\n",
        "x_t = []\n",
        "with open('train_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    x.append(row)\n",
        "    x_t.append(row)\n",
        "\n",
        "#Open train_label file \n",
        "y = []\n",
        "y_t = []\n",
        "with open('train_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    y.append(row)\n",
        "    y_t.append(row)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user nice new signage. Are you not concerned ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A woman who you fucked multiple times saying y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user real talk do you have eyes or were...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hysterical woman like @user \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  @user nice new signage. Are you not concerned ...      0\n",
              "1  A woman who you fucked multiple times saying y...      1\n",
              "2  @user @user real talk do you have eyes or were...      1\n",
              "3  your girlfriend lookin at me like a groupie in...      1\n",
              "4                     Hysterical woman like @user \\n      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJfEVf6YVBx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3849a901-bc91-4bbf-9626-5d36ac0cc9fa"
      },
      "source": [
        "#Read raw text data and label data\n",
        "#Open val_text file \n",
        "x_val = []\n",
        "with open('val_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    x.append(row)\n",
        "    x_val.append(row)\n",
        "\n",
        "#Open val_label file \n",
        "y_val = []\n",
        "with open('train_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    y.append(row)\n",
        "    y_val.append(row)\n",
        "\n",
        "  data_val = pd.DataFrame(zip(x_val, y_val),  columns=['Comments', 'Labels'] )\n",
        "data_val.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user If book Claire wanted to \"stay in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After arriving in the EU refugees make protest...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ðŸ˜³ðŸ‘‡ \\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user Worst thing is if they are that stupid t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user Say's the HYSTERICAL woman. It is woman ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  @user @user If book Claire wanted to \"stay in ...      0\n",
              "1  After arriving in the EU refugees make protest...      1\n",
              "2                                              ðŸ˜³ðŸ‘‡ \\n      1\n",
              "3  @user Worst thing is if they are that stupid t...      1\n",
              "4  @user Say's the HYSTERICAL woman. It is woman ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "j7IHvBcapqab",
        "outputId": "733009a2-b53a-441d-9c5b-adca6b788bc8"
      },
      "source": [
        "#combine both data to dataframe\n",
        "data = pd.DataFrame(zip(x, y),  columns=['Comments', 'Labels'] )\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user nice new signage. Are you not concerned ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A woman who you fucked multiple times saying y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user real talk do you have eyes or were...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hysterical woman like @user \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  @user nice new signage. Are you not concerned ...      0\n",
              "1  A woman who you fucked multiple times saying y...      1\n",
              "2  @user @user real talk do you have eyes or were...      1\n",
              "3  your girlfriend lookin at me like a groupie in...      1\n",
              "4                     Hysterical woman like @user \\n      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p_UFJhXorBC",
        "outputId": "ce352753-9834-4d3c-fe7f-c6272c5aba96"
      },
      "source": [
        "# check the number  of data\n",
        "data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMpYh_rVo2vg",
        "outputId": "8add7f1b-90f8-4b07-aeda-e67fa0534f71"
      },
      "source": [
        "#Identify label data\n",
        "# It is a unbalanced class dataset\n",
        "data['Labels'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5792\n",
              "1    4207\n",
              "        1\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRLqYyhsVp9x"
      },
      "source": [
        "# **Preprocessing**\n",
        "For preprocessing. the process consists of \n",
        "1. tokenize\n",
        "2. lowercase transformation\n",
        "3. Remove punctuation and stopword\n",
        "4. Steming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU-MEZaxVWAF",
        "outputId": "dd4499bd-5919-44f1-8e3f-b489d8fa3fc8"
      },
      "source": [
        "#import important library for preprocessing step\n",
        "import nltk\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_3nxODBVWGy",
        "outputId": "f6d5ed3c-bee7-4f9f-a92e-29bce20ab96d"
      },
      "source": [
        "#create punctuation, stopword and stem \n",
        "punct = string.punctuation #create list of punctuation\n",
        "stopwords = list(STOP_WORDS) #create list of stopword\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "ps = PorterStemmer() #steming\n",
        "STOP_WORDS.add('user') #because the text data contain a lot of user. So \"user\" is added in stopword.\n",
        "nlp.vocab['user'].is_stop # confirm that user is stopword "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WusemTuVWJf"
      },
      "source": [
        "#Create fucction for preprocessing step\n",
        "#the first function is remove punctuation, covert text to lower case\n",
        "def preprocessing_1(text):\n",
        "  txt = re.sub(r'\\d+','', text)\n",
        "  txt = txt.translate(str.maketrans(\"\",\"\",punct))\n",
        "  txt = txt.lower()\n",
        "  txt = txt.strip()\n",
        "  return txt\n",
        "\n",
        "#For the second function; tokenization and remove stopwords\n",
        "def preprocessing_2(text):\n",
        "  txt = word_tokenize(text)\n",
        "  txt = [i for i in txt if not i in stopwords]\n",
        "  txt = txt = \" \".join(txt)\n",
        "  return txt\n",
        "\n",
        "#The last function; stemming\n",
        "def stem(text):\n",
        "  txt = word_tokenize(text)\n",
        "  txt = [ps.stem(i) for i in txt ]\n",
        "  txt = txt = \" \".join(txt)\n",
        "  return txt\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jA13xSl8VWL3",
        "outputId": "bea277ca-bc0f-4603-cc84-b79437315232"
      },
      "source": [
        "#Apply preprocessing function to the dataset\n",
        "data['Comments'] = data['Comments'].apply(lambda x: preprocessing_1(x))\n",
        "data['Comments'] = data['Comments'].apply(lambda x: preprocessing_2(x))\n",
        "data['Comments'] = data['Comments'].apply(lambda x: stem(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nice new signag concern beatlemania style hyst...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>woman fuck multipl time yo dick small complime...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>real talk eye goug rapefug</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>girlfriend lookin like groupi bitch</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hyster woman like</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  nice new signag concern beatlemania style hyst...      0\n",
              "1  woman fuck multipl time yo dick small complime...      1\n",
              "2                         real talk eye goug rapefug      1\n",
              "3                girlfriend lookin like groupi bitch      1\n",
              "4                                  hyster woman like      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou3zuPRpWU17"
      },
      "source": [
        "# **Feature Extraction section**\n",
        "In the process, two feature extraction method were selected \n",
        "  1. CounterVectorizer\n",
        "  2. TfidfVectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooBa1I7mWSgL"
      },
      "source": [
        "#import importance library for feature extraction method\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ2oSCUbgh2-"
      },
      "source": [
        "#split dataset to x and y variables\n",
        "y = data['Labels']\n",
        "x = data['Comments']\n",
        "#applied TF-IDF approach\n",
        "tf=TfidfVectorizer() \n",
        "x_tf = tf.fit_transform(x)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmEbcnYt1z7B"
      },
      "source": [
        "#applied CountVectorizer\n",
        "ct = CountVectorizer()\n",
        "x_ct = ct.fit_transform(x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QYFjMO1gVXW"
      },
      "source": [
        "#Split train and test dataset tf-idf approach\n",
        "X_train, X_test, y_train, y_test =  train_test_split(x_tf, y, test_size = 0.3, random_state =0, shuffle = True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zez1C5PQ1-JH"
      },
      "source": [
        "#Split train and test dataset couter vectorizer approach\n",
        "X_train_c, X_test_c, y_train_c, y_test_c =  train_test_split(x_ct, y, test_size = 0.3, random_state =0, shuffle = True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4pMfrazDqEi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oBtzdT81vLG"
      },
      "source": [
        "\n",
        "\n",
        "# **Oversampling approach**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gRDuMKzexMB"
      },
      "source": [
        "#import library for oversampling\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "os =  RandomOverSampler( )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkpA6Ug-B15a",
        "outputId": "e1c4b2b5-30ae-4553-91c6-6719d0894cd8"
      },
      "source": [
        "#apply Oversampling to x train with TFIDF method \n",
        "X_sm, y_sm = os.fit_sample(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iflsL8RB2O5b",
        "outputId": "a3e2a91c-4b1c-48cd-ba26-d8e3fa81167f"
      },
      "source": [
        "#apply Oversampling to x train with CounterVectorizer method \n",
        "Xc_sm, yc_sm = os.fit_sample(X_train_c, y_train_c)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ADZ7N1exO5",
        "outputId": "36b481e0-5d2a-407b-d9e7-2f94254cbf40"
      },
      "source": [
        "#Check dimension after oversampling approach\n",
        "X_sm.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12180, 14459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtTRNs2v2Yxf",
        "outputId": "61a39434-64f5-4d41-b14f-495a5751ca08"
      },
      "source": [
        "#Check dimension after oversampling approach\n",
        "Xc_sm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12180, 14459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTfm079EZDZw"
      },
      "source": [
        "# **Train data**\n",
        "Three machine learning algorithms are selected for data training \n",
        "1. Logistic regression\n",
        "2. Support vector machine\n",
        "3. Randomforest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcHDo8tCrmIE"
      },
      "source": [
        "**Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGz5DaldexQ8"
      },
      "source": [
        "#Import library\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR4ySmItgwIf"
      },
      "source": [
        "#Create logistic regression model\n",
        "log_class=LogisticRegression()\n",
        "# created dict which use for Gridsearch\n",
        "grid={'C':10.0 **np.arange(-3,4),'penalty':['l1','l2']}"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35c8g_wAgu-6",
        "outputId": "eee0e4b8-f8f8-446f-86aa-3bc1b1636d34"
      },
      "source": [
        "#Applied Gridsearch for parameter tuning and train with TF-IDF as input\n",
        "log=GridSearchCV(estimator=log_class,param_grid=grid,cv=5,n_jobs=-1,scoring='f1_macro')\n",
        "log.fit(X_sm,y_sm)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdJl2QAu2fTG",
        "outputId": "6a7817fb-0b45-498e-b513-48c78264073f"
      },
      "source": [
        "#Applied Gridsearch for parameter tuning and train with Counter vector as input\n",
        "log_c=GridSearchCV(estimator=log_class,param_grid=grid,cv=5,n_jobs=-1,scoring='f1_macro')\n",
        "log_c.fit(Xc_sm,yc_sm)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9EiiU2OQraI"
      },
      "source": [
        "#Predict x_test by 2 model\n",
        "y_pred_log1 = log.predict(X_test)\n",
        "y_pred_log2 = log_c.predict(X_test_c)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqwUP8DZnkH4"
      },
      "source": [
        "#Evaluation training set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW_aFH6JREFP"
      },
      "source": [
        "#import library for evaluation\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEDv3y7UQlNQ",
        "outputId": "5fdff91a-9a52-4b13-f9ba-4ed81095660c"
      },
      "source": [
        "#Evaluation the model with TF-IDF as input\n",
        "f1_score(y_test, y_pred_log1, average='macro')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6787061011208253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRfw_zKPQlUh",
        "outputId": "79330ba2-4ab8-4264-aa1f-b54eaeec63bf"
      },
      "source": [
        "#Evaluation the model with Count vector as input\n",
        "f1_score(y_test, y_pred_log2, average='macro')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6928259658072133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhXQ8DcAreb-"
      },
      "source": [
        "**Random forest classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljgvFYi31liJ"
      },
      "source": [
        "#import library and create Randomforest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_forest = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5kNhE5vdS0T"
      },
      "source": [
        "#create dict use for randomsearch\n",
        "# Number of trees in random forest\n",
        "n_estimators = [50,100,200]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FgFM1NBndTW"
      },
      "source": [
        "Apply random search for parameter optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0nd1Cj7eLAU"
      },
      "source": [
        "#import Randomsearch library\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnMxOJVFdqL-"
      },
      "source": [
        "#parameter tuning by RandomSearch\n",
        "rf_random = RandomizedSearchCV(estimator = clf_forest, \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, cv = 3, verbose=2, \n",
        "                               random_state=42, n_jobs = -1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdI0nUmseM54",
        "outputId": "d674231c-b1eb-4184-c25c-f64ea096c305"
      },
      "source": [
        "#Train model with TF-IDF method\n",
        "rf_random.fit(X_sm,y_sm)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 19.6min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 37.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=None,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [50, 100, 200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2e3vLdQcjFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d45f55-2b53-4a89-925c-3913c612fed3"
      },
      "source": [
        "#Train model with Count vector method\n",
        "rf_random_c = RandomizedSearchCV(estimator = clf_forest, \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, cv = 3, verbose=2, \n",
        "                               random_state=42, n_jobs = -1)\n",
        "rf_random_c.fit(Xc_sm,yc_sm)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 19.2min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 36.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=None,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [50, 100, 200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_VV9b24rrn-"
      },
      "source": [
        "**Support vector machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVUTeo89DInj"
      },
      "source": [
        "#Import and create svm models for train different input (TFIDF, count vector)\n",
        "from sklearn import svm\n",
        "#Fit with TF-IDF\n",
        "svc1 = svm.LinearSVC(C=10)\n",
        "#Fit with Countervectorizer\n",
        "svc2 = svm.LinearSVC(C=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjG5kb6vENAR",
        "outputId": "4b735817-0c83-42b6-aeab-1a29284b203e"
      },
      "source": [
        "#Training data \n",
        "svc1.fit(X_sm,y_sm) #TF-IDF method\n",
        "svc2.fit(Xc_sm,yc_sm) #CounterVectorizer approach"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wesTE4BlM7B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RwbxYDNY2z0"
      },
      "source": [
        "# **Predict and Evaluation from Test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVx9dCIMhQc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a323a963-6fc6-404a-fd8a-4387ada9b22b"
      },
      "source": [
        "#Read Test dataset with include raw text and labels\n",
        "#Open test_text \n",
        "xt = []\n",
        "with open('test_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    xt.append(row)\n",
        "\n",
        " #Open test_label\n",
        "yt = []\n",
        "with open('test_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    yt.append(row)   \n",
        "\n",
        "#Create dataframe with combine raw text and label\n",
        "data_t = pd.DataFrame(zip(xt, yt),  columns=['Comments', 'Labels'] )\n",
        "data_t.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user , you are correct that Reid certainly is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Whoever just unfollowed me you a bitch \\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user Those People Invaded Us!!! They DO...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stop JUDGING bitches by there cover, jus cuz s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how about i knock heads off and send them gift...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  @user , you are correct that Reid certainly is...      0\n",
              "1          Whoever just unfollowed me you a bitch \\n      1\n",
              "2  @user @user Those People Invaded Us!!! They DO...      1\n",
              "3  stop JUDGING bitches by there cover, jus cuz s...      1\n",
              "4  how about i knock heads off and send them gift...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QqNk8RhthRj5",
        "outputId": "ec38bbe5-e046-43da-81a4-1110738187e7"
      },
      "source": [
        "#Preprocessing in test file\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: preprocessing_1(x))\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: preprocessing_2(x))\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: stem(x))\n",
        "\n",
        "data_t.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>correct reid certainli weasel sadli weve got w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unfollow bitch</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>peopl invad bele right americafirst open hou i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stop judg bitch cover ju cuz bad dont mean cat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>knock head send gift wrap mom hou dumb raggedi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  correct reid certainli weasel sadli weve got w...      0\n",
              "1                                     unfollow bitch      1\n",
              "2  peopl invad bele right americafirst open hou i...      1\n",
              "3  stop judg bitch cover ju cuz bad dont mean cat...      1\n",
              "4  knock head send gift wrap mom hou dumb raggedi...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tp5w4ULk7d_"
      },
      "source": [
        "#Feature extraction in test dataset by use two method\n",
        "x_tf_test = tf.transform(data_t['Comments']) #TF-IDF\n",
        "xc_tf_test = ct.transform(data_t['Comments']) #CounterVectorizer"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Ku4TwxJz_2"
      },
      "source": [
        "**Evaluated test dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hg04FqYKeEs"
      },
      "source": [
        "support vector machine model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDenOzbZJ8hb",
        "outputId": "dc0116b3-ae9b-48b3-f534-091327b90224"
      },
      "source": [
        "#Evaluate support vector machine with tf-idf approach\n",
        "y_svc1 = svc1.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_svc1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.38      0.49      1718\n",
            "           1       0.47      0.75      0.58      1252\n",
            "\n",
            "    accuracy                           0.53      2970\n",
            "   macro avg       0.57      0.56      0.53      2970\n",
            "weighted avg       0.59      0.53      0.52      2970\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ky00k2rJ3wA",
        "outputId": "01861cee-b6b0-48f6-f3cc-00b9c5ee6132"
      },
      "source": [
        "#Evaluate support vector machine with countervectorize approach\n",
        "y_svc2 = svc2.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_svc2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.42      0.52      1718\n",
            "           1       0.47      0.71      0.57      1252\n",
            "\n",
            "    accuracy                           0.55      2970\n",
            "   macro avg       0.57      0.57      0.54      2970\n",
            "weighted avg       0.59      0.55      0.54      2970\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxaQvA2jKhyO"
      },
      "source": [
        "logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YnoM3FkgYjU",
        "outputId": "2f50cf3c-e27c-466b-f71a-70e44de7bdfa"
      },
      "source": [
        "#Evaluate Logistic regression machine with tf-idf approach\n",
        "y_log1 = log.predict(x_tf_test)\n",
        "f1_score(data_t['Labels'], y_log1, average='macro')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5341770940498122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyiIIaYB3W0j",
        "outputId": "3ee6bc0a-882b-450c-d266-43ed0b405ee4"
      },
      "source": [
        "#Evaluate Logistic regression machine with CounterVectorize approach\n",
        "y_logc = log_c.predict(xc_tf_test)\n",
        "f1_score(data_t['Labels'], y_logc, average='macro')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5499935754816432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BONB5zcNgX74"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G4LuEFAFR1x"
      },
      "source": [
        "Randomforest model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVMDtaitrpxE",
        "outputId": "3365a181-7412-4c34-9464-bd0083690555"
      },
      "source": [
        "#Evaluate Randomforest with tf-idf approach\n",
        "y_rfc = rf_random.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_rfc))\n",
        "f1_score(data_t['Labels'], y_rfc, average='macro')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.22      0.33      1718\n",
            "           1       0.45      0.87      0.59      1252\n",
            "\n",
            "    accuracy                           0.49      2970\n",
            "   macro avg       0.58      0.55      0.46      2970\n",
            "weighted avg       0.60      0.49      0.44      2970\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.463785608607547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w8myecpnMKv",
        "outputId": "5c92bf2e-24bc-42df-a401-fc33d45e6320"
      },
      "source": [
        "#Evaluate Randomforest with CounterVectorizer approach\n",
        "y_rf = rf_random.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_rf))\n",
        "f1_score(data_t['Labels'], y_rf, average='macro')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.14      0.24      1718\n",
            "           1       0.44      0.92      0.60      1252\n",
            "\n",
            "    accuracy                           0.47      2970\n",
            "   macro avg       0.58      0.53      0.42      2970\n",
            "weighted avg       0.60      0.47      0.39      2970\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41711668811234154"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFjFbJnW3iB6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXvvYiFpnm2V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}