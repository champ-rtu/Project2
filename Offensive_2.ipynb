{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Offensive_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpU/30UDdpdIG6wM2vyh24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/champ-rtu/Project2/blob/main/Offensive_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h70ollhIFl25"
      },
      "source": [
        "#Import Libraty \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2pF6vFS7sL2"
      },
      "source": [
        "**There are 6 section in this project**\n",
        "1. Import data\n",
        "2. Preprocessing \n",
        "3. Numerical representation\n",
        "4. Oversampling\n",
        "5. Train the data by machine learning models\n",
        "6. Evaluation in Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHoc_c1HG_mX"
      },
      "source": [
        "#**Import text data** \n",
        "Train data is imported in this section\n",
        "there are two data in this project which is raw text and label data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoXmFWJuG8uv"
      },
      "source": [
        "#Read raw text data and label data\n",
        "#Open train_text file \n",
        "x = []\n",
        "x_t = []\n",
        "with open('train_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    x.append(row)\n",
        "    x_t.append(row)\n",
        "\n",
        "#Open train_label file \n",
        "y = []\n",
        "y_t = []\n",
        "with open('train_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    y.append(row)\n",
        "    y_t.append(row)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MZMdE7-CG8zh",
        "outputId": "0d841eea-3b0e-40e5-af73-8a408766ea7f"
      },
      "source": [
        "#combine both data to dataframe\n",
        "data = pd.DataFrame(zip(x, y),  columns=['Comments', 'Labels'] )\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user Bono... who cares. Soon people will unde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user Eight years the republicans denied obama...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user Get him some line help. He is gonna be j...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user @user She is great. Hi Fiona! \\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user She has become a parody unto herself? Sh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  @user Bono... who cares. Soon people will unde...      0\n",
              "1  @user Eight years the republicans denied obama...      1\n",
              "2  @user Get him some line help. He is gonna be j...      0\n",
              "3             @user @user She is great. Hi Fiona! \\n      0\n",
              "4  @user She has become a parody unto herself? Sh...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOycNSLBG81r",
        "outputId": "2e0680ff-060f-47d8-e2cc-8d67d778f14a"
      },
      "source": [
        "# check the number  of data\n",
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11916, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rET65INbG83y",
        "outputId": "c8193cab-3c3d-4f60-bfdd-970459ff0c0b"
      },
      "source": [
        "#Identify label data\n",
        "# It is a unbalanced class dataset\n",
        "data['Labels'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7975\n",
              "1    3941\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOPiMmrCHbkE"
      },
      "source": [
        "# **Preprocessing**\n",
        "For preprocessing. the process consists of \n",
        "1. tokenize\n",
        "2. lowercase transformation\n",
        "3. Remove punctuation and stopword\n",
        "4. Steming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVz5H9IMHYjB",
        "outputId": "d3899275-8200-41fb-d47c-b867a19bde68"
      },
      "source": [
        "#import library for preprocessing step\n",
        "import nltk\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nprUoQWSHYly",
        "outputId": "047fdd65-56e4-48ac-bd85-ec8f17b7d9f8"
      },
      "source": [
        "#create punctuation, stopword and stem \n",
        "punct = string.punctuation #create list of punctuation\n",
        "stopwords = list(STOP_WORDS) #create list of stopword\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "ps = PorterStemmer() #steming\n",
        "STOP_WORDS.add('user') #because the text data contain a lot of user. So \"user\" is added in stopword.\n",
        "nlp.vocab['user'].is_stop # confirm that user is stopword "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raA0O1EkHYn9"
      },
      "source": [
        "#Create fucction for preprocessing step\n",
        "#the first function is remove punctuation, covert text to lower case\n",
        "def preprocessing_1(text):\n",
        "  txt = re.sub(r'\\d+','', text)\n",
        "  txt = txt.translate(str.maketrans(\"\",\"\",punct))\n",
        "  txt = txt.lower()\n",
        "  txt = txt.strip()\n",
        "  return txt\n",
        "\n",
        "#For the second function; tokenization and remove stopwords\n",
        "def preprocessing_2(text):\n",
        "  txt = word_tokenize(text)\n",
        "  txt = [i for i in txt if not i in stopwords]\n",
        "  txt = txt = \" \".join(txt)\n",
        "  return txt\n",
        "\n",
        "#The last function; stemming\n",
        "def stem(text):\n",
        "  txt = word_tokenize(text)\n",
        "  txt = [ps.stem(i) for i in txt ]\n",
        "  txt = txt = \" \".join(txt)\n",
        "  return txt\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ATIgvbIhHYp7",
        "outputId": "869d7748-0d5c-4731-efe9-9c4dd9dd7013"
      },
      "source": [
        "#Apply preprocessing function to the dataset\n",
        "data['Comments'] = data['Comments'].apply(lambda x: preprocessing_1(x))\n",
        "data['Comments'] = data['Comments'].apply(lambda x: preprocessing_2(x))\n",
        "data['Comments'] = data['Comments'].apply(lambda x: stem(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bono care soon peopl understand gain follow ph...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>year republican deni obama ’ s pick breitbart ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>line help gon na fine game went progress read ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>great hi fiona</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>parodi unto certainli taken heat anwel idiot o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  bono care soon peopl understand gain follow ph...      0\n",
              "1  year republican deni obama ’ s pick breitbart ...      1\n",
              "2  line help gon na fine game went progress read ...      0\n",
              "3                                     great hi fiona      0\n",
              "4  parodi unto certainli taken heat anwel idiot o...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaDXCfTLHy2R"
      },
      "source": [
        "# **Feature exaction section**\n",
        "In the process, two feature extraction method were selected \n",
        "  1. CounterVectorizer\n",
        "  2. TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9hSslJHYsG"
      },
      "source": [
        "#import importance library for feature extraction method\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6B0G37cH03P"
      },
      "source": [
        "#split dataset to x and y variables\n",
        "y = data['Labels']\n",
        "x = data['Comments']\n",
        "#applied TF-IDF approach\n",
        "tf=TfidfVectorizer() \n",
        "x_tf = tf.fit_transform(x)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-7QoccmH05t"
      },
      "source": [
        "#applied CountVectorizer\n",
        "ct = CountVectorizer()\n",
        "x_ct = ct.fit_transform(x)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qti879IH07y"
      },
      "source": [
        "#Split train and test dataset tf-idf approach\n",
        "X_train, X_test, y_train, y_test =  train_test_split(x_tf, y, test_size = 0.3,\n",
        "                                                     random_state =0, shuffle = True)\n",
        "#Split train and test dataset couter vectorizer approach\n",
        "X_train_c, X_test_c, y_train_c, y_test_c =  train_test_split(x_ct, y, test_size = 0.3, \n",
        "                                                             random_state =0, shuffle = True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd_R21ViIL0U"
      },
      "source": [
        "# **Oversampling approach**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ7xvANoH0zI",
        "outputId": "6a6dd739-a5fa-4499-87ca-f1241f7ed488"
      },
      "source": [
        "#import library for oversampling\n",
        "#in this task SMOTE was selected for oversampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o__A5MJhH0-F",
        "outputId": "233b18d5-7380-4781-dca6-4373bcaf86ce"
      },
      "source": [
        "#Applied SMOTE to x_train \n",
        "X_os,y_os  = oversample.fit_resample(X_train, y_train) #TF_IDF\n",
        "Xc_os,yc_os  = oversample.fit_resample(X_train_c, y_train_c) #CounterVectorizer\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntid_FV05mGy",
        "outputId": "8ce76273-73ca-4055-bb1d-e643ed481eb3"
      },
      "source": [
        "#Check dimension after oversampling approach\n",
        "X_os.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11076, 13826)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U82yTx5Inui"
      },
      "source": [
        "# **Train data**\n",
        "Three machine learning algorithms are selected for data training \n",
        "1. Logistic regression\n",
        "2. Support vector machine\n",
        "3. Randomforest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vHq9RHCIrDC"
      },
      "source": [
        "**Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWAOIZniIjT0"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0e0cAZ6IjWt"
      },
      "source": [
        "#Create logistic regression model\n",
        "log_class=LogisticRegression()\n",
        "# created dict which use for Gridsearch\n",
        "grid={'C':10.0 **np.arange(-3,4),'penalty':['l1','l2']}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwmoJmCeIjYX",
        "outputId": "1918aeb3-13d8-447b-e672-fa14b331d2d9"
      },
      "source": [
        "#Applied Gridsearch for parameter tuning and train with TF-IDF as input\n",
        "log=GridSearchCV(estimator=log_class,param_grid=grid,cv=5,n_jobs=-1,scoring='f1_macro')\n",
        "log.fit(X_os,y_os)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyAjMgwPIja0",
        "outputId": "2daffed9-4e9e-4599-d811-94ed550b83fe"
      },
      "source": [
        "#Applied Gridsearch for parameter tuning and train with Count Vector as input\n",
        "log_c=GridSearchCV(estimator=log_class,param_grid=grid,cv=5,n_jobs=-1,scoring='f1_macro')\n",
        "log_c.fit(Xc_os,yc_os)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_macro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCKg3gUnKAOq"
      },
      "source": [
        "Evaluation from trainning set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxW3Ai3dIjc8"
      },
      "source": [
        "#import library for evaluation\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,f1_score"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcrNCT_nIje1",
        "outputId": "6076dbc1-0e33-48e8-dc28-2a30af701c7a"
      },
      "source": [
        "#Prediction and Evaluation the model with TF-IDF as input for training phase\n",
        "y_pred_log=log.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_log))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.72      0.76      2437\n",
            "           1       0.51      0.62      0.56      1138\n",
            "\n",
            "    accuracy                           0.69      3575\n",
            "   macro avg       0.66      0.67      0.66      3575\n",
            "weighted avg       0.71      0.69      0.70      3575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7dWlBbcKLe8",
        "outputId": "4b3c5ce9-5778-4727-d27c-fe307a9ce434"
      },
      "source": [
        "#Prediction and Evaluation the model with CounterVectorizer as input for training phase\n",
        "y_pred_logc=log_c.predict(X_test_c)\n",
        "print(classification_report(y_test,y_pred_logc))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.69      0.74      2437\n",
            "           1       0.49      0.64      0.56      1138\n",
            "\n",
            "    accuracy                           0.67      3575\n",
            "   macro avg       0.65      0.67      0.65      3575\n",
            "weighted avg       0.70      0.67      0.68      3575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVMMWUb4Jpi5"
      },
      "source": [
        "**Support vector machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VvJybhcJt4V"
      },
      "source": [
        "#Import and create svm models for train different input (TFIDF, count vector)\n",
        "from sklearn import svm\n",
        "#Fit with TF-IDF\n",
        "svc1 = svm.LinearSVC(C=10)\n",
        "#Fit with Countervectorizer\n",
        "svc2 = svm.LinearSVC(C=10)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Txhz4SJt6w",
        "outputId": "fbddffd1-e362-4932-9f26-da61a18f91db"
      },
      "source": [
        "#Training data \n",
        "svc1.fit(X_os,y_os)  #TF-IDF method\n",
        "svc2.fit(Xc_sm,yc_sm) #CounterVectorizer approach\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5u5cWKLKbYJ"
      },
      "source": [
        "Evaluate svc model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOK5fDi2Jzxj",
        "outputId": "22d1ee3a-8a91-4e8d-9a7b-3938c45c066f"
      },
      "source": [
        "#Prediction and Evaluation the model with TF-IDF as input for training phase\n",
        "y_pred=svc1.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.70      0.75      2437\n",
            "           1       0.49      0.63      0.55      1138\n",
            "\n",
            "    accuracy                           0.68      3575\n",
            "   macro avg       0.65      0.66      0.65      3575\n",
            "weighted avg       0.70      0.68      0.69      3575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WECltMVbJ65c",
        "outputId": "baba308a-d69d-4a9c-bff9-b5288df092e7"
      },
      "source": [
        "#Prediction and Evaluation the model with CounterVectorizer as input for training phase\n",
        "y_pred_c=svc2.predict(X_test_c)\n",
        "print(classification_report(y_test,y_pred_c))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.77      0.78      2437\n",
            "           1       0.54      0.58      0.56      1138\n",
            "\n",
            "    accuracy                           0.71      3575\n",
            "   macro avg       0.67      0.68      0.67      3575\n",
            "weighted avg       0.72      0.71      0.71      3575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9F7UeXpJz0a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8l6i_mcJ0E8"
      },
      "source": [
        "**Randomforest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uosjrx1AJt9B"
      },
      "source": [
        "#import library and create Randomforest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Create models\n",
        "clf_forest = RandomForestClassifier() #model for TFIDF\n",
        "\n",
        "clf_forestc = RandomForestClassifier()#Model for CounterVectorizer"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1BrHhztgZfM"
      },
      "source": [
        "Parameter tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHafnAO9O783"
      },
      "source": [
        "#import library and create Randomforest model\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEFBYU7VPEeo"
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [50,100,200]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvgAQ9EcO7_3"
      },
      "source": [
        "#parameter tuning by RandomSearch\n",
        "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, cv = 3, verbose=2, \n",
        "                               random_state=42, n_jobs = -1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIlKSN2LQXjT",
        "outputId": "bd756f77-5ea0-4fc1-96b5-9c41ef406951"
      },
      "source": [
        "#Train model with TF-IDF input\n",
        "rf_random.fit(X_os,y_os)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 31.7min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 61.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=None,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [50, 100, 200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbRXzrsGte70",
        "outputId": "99d75c8d-2508-43a3-f8fc-6f46d51cb1a7"
      },
      "source": [
        "#check best parameter for this condition\n",
        "rf_random.best_params_"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8qoPQb0sL_4",
        "outputId": "f519c529-1f1d-4579-87fa-5754af240e33"
      },
      "source": [
        "#Train model with Count vector input\n",
        "rf_randomc = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, cv = 3, verbose=2, \n",
        "                               random_state=42, n_jobs = -1)\n",
        "rf_randomc.fit(X_os,y_os)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 31.7min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 61.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=None,\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [50, 100, 200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9EWuJzsILRn",
        "outputId": "9c662932-b693-4856-91bf-51e0d8de93bc"
      },
      "source": [
        "#check best parameter for this condition\n",
        "rf_randomc.best_params_"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': False,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2woUBX5TsyRl",
        "outputId": "d7c1718d-8257-415c-f722-641dca7ddf95"
      },
      "source": [
        "#Prediction and Evaluation the model with TF-IDF as input for training phase\n",
        "y_pred_rf = rf_random.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_rf))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84      2437\n",
            "           1       0.66      0.53      0.59      1138\n",
            "\n",
            "    accuracy                           0.77      3575\n",
            "   macro avg       0.73      0.70      0.71      3575\n",
            "weighted avg       0.76      0.77      0.76      3575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFF-wI_FJ7qs",
        "outputId": "88a09995-5e6d-423f-c838-d90288798132"
      },
      "source": [
        "#Prediction and Evaluation the model with CounterVectorizer as input for training phase\n",
        "y_pred_rfc = rf_randomc.predict(X_test_c)\n",
        "print(classification_report(y_test,y_pred_rfc))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84      2437\n",
            "           1       0.70      0.40      0.51      1138\n",
            "\n",
            "    accuracy                           0.75      3575\n",
            "   macro avg       0.73      0.66      0.67      3575\n",
            "weighted avg       0.74      0.75      0.73      3575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YSMJgzBK5m7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h9hYrJ3JuAl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoCOVTtlK3dV"
      },
      "source": [
        "# **Predict and Evaluation from Test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "mKTnQH6eK9Eg",
        "outputId": "6ef031a1-a15f-4ad3-b833-6dd53a8e7797"
      },
      "source": [
        "#Read Test dataset with include raw text and labels\n",
        "#Open test_text \n",
        "xt = []\n",
        "with open('test_text.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  \n",
        "  for row in data:\n",
        "    xt.append(row)\n",
        "\n",
        " #Open test_label\n",
        "yt = []\n",
        "with open('test_labels.txt', 'r', encoding='utf-8') as f:\n",
        "  data = f.read().split('\\n')\n",
        "\n",
        "  for row in data:\n",
        "    yt.append(row)   \n",
        "\n",
        "data_t = pd.DataFrame(zip(xt, yt),  columns=['Comments', 'Labels'] )\n",
        "data_t.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#ibelieveblaseyford is liar she is fat ugly li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@user @user @user I got in a pretty deep debat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...if you want more shootings and more death, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Angels now have 6 runs. Five of them have come...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Travel #Movies and Unix #Fortune combined  Vi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  #ibelieveblaseyford is liar she is fat ugly li...      1\n",
              "1  @user @user @user I got in a pretty deep debat...      0\n",
              "2  ...if you want more shootings and more death, ...      0\n",
              "3  Angels now have 6 runs. Five of them have come...      0\n",
              "4  #Travel #Movies and Unix #Fortune combined  Vi...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pnDjM72CK9HD",
        "outputId": "2a4b2f03-7c00-49a0-94f5-e004b0aefa8c"
      },
      "source": [
        "#Preprocessing in test file\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: preprocessing_1(x))\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: preprocessing_2(x))\n",
        "data_t['Comments'] = data_t['Comments'].apply(lambda x: stem(x))\n",
        "#data_t['Comments'] = data_t['Comments'].apply(lambda x: lemma(x))\n",
        "data_t.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ibelieveblaseyford liar fat ugli libreal snowf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>got pretti deep debat friend told latino trump...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>want shoot death listen aclu black live matter...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>angel run come courtesi mike trout homer trout...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>travel movi unix fortun combin visit salisburi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Comments Labels\n",
              "0  ibelieveblaseyford liar fat ugli libreal snowf...      1\n",
              "1  got pretti deep debat friend told latino trump...      0\n",
              "2  want shoot death listen aclu black live matter...      0\n",
              "3  angel run come courtesi mike trout homer trout...      0\n",
              "4  travel movi unix fortun combin visit salisburi...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az1rG013K9JS"
      },
      "source": [
        "#Feature extraction in test dataset by use two method\n",
        "x_tf_test = tf.transform(data_t['Comments']) #TF-IDF\n",
        "xc_tf_test = ct.transform(data_t['Comments']) #CounterVectorizer"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VooxMh38_1Sj"
      },
      "source": [
        "**Evaluated test dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ATVUPWLJ2Bq"
      },
      "source": [
        "Evaluation support vector machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_njXvX9cK9Nd",
        "outputId": "1d31683e-da0f-4d6e-d6b0-a48731ab9788"
      },
      "source": [
        "#Evaluate support vector machine with tf-idf approach\n",
        "y_svc1 = svc1.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_svc1))\n",
        "f1_score(data_t['Labels'], y_svc1, average='macro')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.75      0.79       620\n",
            "           1       0.49      0.62      0.55       240\n",
            "\n",
            "    accuracy                           0.71       860\n",
            "   macro avg       0.66      0.68      0.67       860\n",
            "weighted avg       0.74      0.71      0.72       860\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6686484691672043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1rs_tUkK9Px",
        "outputId": "9598e982-ccf7-4091-e800-2608f4fa8cd5"
      },
      "source": [
        "#Evaluate support vector machine with countervectorize approach\n",
        "y_svc2 = svc2.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_svc2))\n",
        "f1_score(data_t['Labels'], y_svc2, average='macro')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82       620\n",
            "           1       0.55      0.64      0.59       240\n",
            "\n",
            "    accuracy                           0.75       860\n",
            "   macro avg       0.70      0.72      0.71       860\n",
            "weighted avg       0.77      0.75      0.76       860\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7071804392935841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kasdrdMJKHFo"
      },
      "source": [
        "Evaluate Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sJYarPgLHaC",
        "outputId": "121d055b-6b8f-4dfb-c897-84d809ab7728"
      },
      "source": [
        "#Evaluate Logistic regression machine with tf-idf approach\n",
        "y_log1 = log.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'],y_log1))\n",
        "f1_score(data_t['Labels'], y_log1, average='macro')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.81       620\n",
            "           1       0.52      0.60      0.56       240\n",
            "\n",
            "    accuracy                           0.73       860\n",
            "   macro avg       0.68      0.69      0.69       860\n",
            "weighted avg       0.75      0.73      0.74       860\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6850808498063075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae1AFMjaLHcl",
        "outputId": "21fd6fbf-4d41-4ffc-9e60-9eb55573f2dc"
      },
      "source": [
        "#Evaluate Logistic regression machine with CounterVectorize approach\n",
        "y_logc = log_c.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'], y_logc))\n",
        "f1_score(data_t['Labels'], y_logc, average='macro')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.80       620\n",
            "           1       0.51      0.60      0.55       240\n",
            "\n",
            "    accuracy                           0.73       860\n",
            "   macro avg       0.67      0.69      0.68       860\n",
            "weighted avg       0.74      0.73      0.73       860\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6771725361843104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POpS8KsWKaCF"
      },
      "source": [
        "Evaluate Randomforest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXCfQtlNLHhQ",
        "outputId": "e050517c-4146-4d47-9b86-a90639489a1a"
      },
      "source": [
        "#Evaluate Randomforest with tf-idf approach\n",
        "y_for = rf_random.predict(x_tf_test)\n",
        "print(classification_report(data_t['Labels'], y_for))\n",
        "f1_score(data_t['Labels'], y_for, average='macro')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.88       620\n",
            "           1       0.71      0.55      0.62       240\n",
            "\n",
            "    accuracy                           0.81       860\n",
            "   macro avg       0.78      0.73      0.75       860\n",
            "weighted avg       0.80      0.81      0.81       860\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7492170958376124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgYaqtHGLHjH",
        "outputId": "b6f89eb5-5233-4a02-c3e6-09d1196d5406"
      },
      "source": [
        "#Evaluate Randomforest with CounterVectorizer approach\n",
        "yc_for = rf_randomc.predict(xc_tf_test)\n",
        "print(classification_report(data_t['Labels'], yc_for))\n",
        "f1_score(data_t['Labels'], yc_for, average='macro')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.87       620\n",
            "           1       0.73      0.40      0.52       240\n",
            "\n",
            "    accuracy                           0.79       860\n",
            "   macro avg       0.76      0.67      0.69       860\n",
            "weighted avg       0.78      0.79      0.77       860\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6912989374940174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}